package cz.adaptech.tesseract4android.sample;

import androidx.core.app.ActivityCompat;
import androidx.lifecycle.MutableLiveData;
import androidx.lifecycle.ViewModelStore;
import androidx.lifecycle.ViewModelStoreOwner;

import android.Manifest;
import android.content.pm.PackageManager;
import android.graphics.Bitmap;
import android.os.Bundle;
import android.util.Log;
import android.view.SurfaceView;
import android.view.WindowManager;
import android.widget.Button;
import android.widget.Toast;

import com.googlecode.tesseract.android.TessBaseAPI;

import org.jetbrains.annotations.NotNull;
import org.opencv.android.BaseLoaderCallback;
import org.opencv.android.CameraActivity;
import org.opencv.android.CameraBridgeViewBase;
import org.opencv.android.LoaderCallbackInterface;
import org.opencv.android.OpenCVLoader;
import org.opencv.android.Utils;
import org.opencv.core.Mat;
import org.opencv.imgproc.Imgproc;

import cz.adaptech.tesseract4android.sample.ui.main.MainViewModel;

//public class MainActivity extends AppCompatActivity {


//    @Override
//    protected void onCreate(Bundle savedInstanceState) {
//        super.onCreate(savedInstanceState);
//        getWindow().addFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON);
//        if (!OpenCVLoader.initDebug()) {
//            Log.d(TAG, "Main OpenCV not loaded");
//        } else {
//            Log.d(TAG, "Main OpenCV loaded");
//        }
//        setContentView(R.layout.activity_main);
//        if (savedInstanceState == null) {
//            getSupportFragmentManager().beginTransaction()
//                    .replace(R.id.container, MainFragment.newInstance())
//                    .commitNow();
//        }
//    }
//}
public class MainActivityOld extends CameraActivity implements CameraBridgeViewBase.CvCameraViewListener2, ViewModelStoreOwner {
    private static final String TAG = "LOG_TAG";

    private static final int CAMERA_PERMISSION_REQUEST = 1;

    private CameraBridgeViewBase mOpenCvCameraView;

    private TessBaseAPI mTess;

    boolean buttonClick = false;

    private final MutableLiveData<String> result = new MutableLiveData<>();
    private final MutableLiveData<Boolean> processing = new MutableLiveData<>(false);
    private ViewModelStore viewModelStore = new ViewModelStore();
    private MainViewModel viewModel;
    private final MutableLiveData<String> progress = new MutableLiveData<>();
    private boolean stopped;


    private long mFrameCounter = 0;
    private long mStartTime = 0;

    private BaseLoaderCallback mLoaderCallback = new BaseLoaderCallback(this) {
        @Override
        public void onManagerConnected(int status) {
            if (status == LoaderCallbackInterface.SUCCESS) {
                Log.i(TAG, "OpenCV loaded successfully");

                mOpenCvCameraView.enableView();
            } else {
                super.onManagerConnected(status);
            }
        }
    };

    @Override
    public void onCreate(Bundle savedInstanceState) {
        Log.i(TAG, "called onCreate");
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);


        if(OpenCVLoader.initDebug()){
            Log.d(TAG, "OpenCV initialized");
        }



        getWindow().addFlags(WindowManager.LayoutParams.FLAG_KEEP_SCREEN_ON);

        // Permissions for Android 6+
        ActivityCompat.requestPermissions(
                this,
                new String[]{Manifest.permission.CAMERA},
                CAMERA_PERMISSION_REQUEST
        );

        setContentView(R.layout.activity_main);

        mOpenCvCameraView = findViewById(R.id.main_surface);
//        mOpenCvCameraView = findViewById(R.id.image);

        mOpenCvCameraView.setVisibility(SurfaceView.VISIBLE);

        mOpenCvCameraView.setCvCameraViewListener(this);

        Button button = (Button) findViewById(R.id.start);
        button.setOnClickListener(v -> {
            Log.d(TAG, "Button Pressed");
            buttonClick = true;
        });



//        String dataPath = new File(getBaseContext().getFilesDir(), "tesseract").getAbsolutePath();

//         Initialize API for specified language (can be called multiple times during Tesseract lifetime)
//        if (!mTess.init(dataPath, "eng")) {
//            // Error initializing Tesseract (wrong/inaccessible data path or not existing language file)
//            mTess.recycle();
//            Log.d(TAG, "onCreate: Failed & recycled");
//            return;
//        }
//        mTess.setVariable(TessBaseAPI.VAR_CHAR_WHITELIST, "0123456789a
//        bcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ");
//        mTess.setPageSegMode(TessBaseAPI.PageSegMode.PSM_AUTO);


        // Copy sample image and language data to storage
//        Assets.extractAssets(getBaseContext());
//
//            String dataPath = Assets.getTessDataPath(requireContext());
//            String language = Assets.getLanguage();
//            viewModel.initTesseract(dataPath, language, TessBaseAPI.OEM_LSTM_ONLY);

        mTess = new TessBaseAPI();
        Assets.extractAssets(getBaseContext());

        String dataPath = Assets.getTessDataPath(getBaseContext());
        String language = Assets.getLanguage();

        if (!mTess.init(dataPath, "eng")) {
            // Error initializing Tesseract (wrong/inaccessible data path or not existing language file)
            mTess.recycle();
            Log.d(TAG, "if (!mTess.init(dataPath, \"eng\")) {");
            return;
        }
//        mTess.init(DATA_PATH, LANGUAGE);
//        mTess.setVariable(TessBaseAPI.VAR_CHAR_WHITELIST, "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ");
//        mTess.setPageSegMode(TessBaseAPI.PageSegMode.PSM_AUTO);
    }

    @Override
    public void onRequestPermissionsResult(int requestCode, @NotNull String[] permissions, @NotNull int[] grantResults) {
        if (requestCode == CAMERA_PERMISSION_REQUEST) {
            if (grantResults.length > 0 && grantResults[0] == PackageManager.PERMISSION_GRANTED) {
                mOpenCvCameraView.setCameraPermissionGranted();
            } else {
                String message = "Camera permission was not granted";
                Log.e(TAG, message);
                Toast.makeText(this, message, Toast.LENGTH_LONG).show();
            }
        } else {
            Log.e(TAG, "Unexpected permission request");
        }
    }

    @Override
    public void onPause() {
        super.onPause();
        if (mOpenCvCameraView != null)
            mOpenCvCameraView.disableView();
    }

    @Override
    public void onResume() {
        super.onResume();
        if (!OpenCVLoader.initDebug()) {
            Log.d(TAG, "Internal OpenCV library not found. Using OpenCV Manager for initialization");
            OpenCVLoader.initAsync(OpenCVLoader.OPENCV_VERSION, this, mLoaderCallback);
        } else {
            Log.d(TAG, "OpenCV library found inside package. Using it!");
            mLoaderCallback.onManagerConnected(LoaderCallbackInterface.SUCCESS);
        }
    }

    @Override
    public void onDestroy() {
        super.onDestroy();
        viewModelStore.clear();
        if (mOpenCvCameraView != null)
            mOpenCvCameraView.disableView();
    }

    @Override
    public void onCameraViewStarted(int width, int height) {
        mFrameCounter = 0;
        mStartTime = System.currentTimeMillis();
    }

    @Override
    public void onCameraViewStopped() {
    }

//    @Override
//    public Mat onCameraFrame(CameraBridgeViewBase.CvCameraViewFrame frame) {
//        // get current camera frame as OpenCV Mat object
//        Mat mat = frame.gray();
//        return mat;
//    }
//    @Override
//    public Mat onCameraFrame(CameraBridgeViewBase.CvCameraViewFrame frame) {
//        mFrameCounter++;
//        // get current camera frame as OpenCV Mat object
//        Mat mat;
//        // extract text from bitmap using Tesseract
//        if(buttonClick){
//            mat = frame.gray();
//            buttonClick = false;
//            // convert Mat to Bitmap
//            Bitmap bitmap = Bitmap.createBitmap(mat.cols(), mat.rows(), Bitmap.Config.ARGB_8888);
//            Utils.matToBitmap(mat, bitmap);
//            long currentTime = System.currentTimeMillis();
//            double fps = mFrameCounter / ((currentTime - mStartTime) / 1000.0);
//            mTess.setImage(bitmap);
//            String text = mTess.getUTF8Text();
//
//            // log text to console
//            Log.d(TAG, "Detected text ("+fps+" fps): " + text);
//        }else{
//            mat = frame.gray();
//        }
//        return mat;
//    }

    @Override
    public Mat onCameraFrame(CameraBridgeViewBase.CvCameraViewFrame frame) {
        mFrameCounter++;
        Mat rgba = frame.gray();
        Bitmap bmp = Bitmap.createBitmap(rgba.cols(), rgba.rows(), Bitmap.Config.ARGB_8888);
        Utils.matToBitmap(rgba, bmp);

        // Convert the bitmap to a format supported by Tesseract
        bmp = bmp.copy(Bitmap.Config.ARGB_8888, true);
        if (buttonClick) {
            buttonClick = false;
                // Convert the camera frame to a bitmap


                mTess.setImage(bmp);
                String text = mTess.getUTF8Text();
                Log.d("OCR Result", text);

                // Release Tesseract when you don't want to use it anymore
            mTess.recycle();
            }
        Mat returning = rgba.clone();
        Utils.bitmapToMat(bmp, returning);
        return returning;
    }

//    @Override
    public Mat onCameraFrameOld(CameraBridgeViewBase.CvCameraViewFrame frame) {
        mFrameCounter++;
        // get current camera frame as OpenCV Mat object
        Mat mat;
        // extract text from bitmap using Tesseract
        mat = frame.rgba();
////        Imgproc.cvtColor(mat, grayImage, Imgproc.COLOR_BGR2GRAY);
//        Mat edges = new Mat();
//        Imgproc.Canny(mat, edges, 100, 200);
//        mat = edges;

        if(buttonClick){
//            mat = frame.gray();
            buttonClick = false;
//            recognizeImage(mat);

            Mat grayImage = new Mat();
            Imgproc.cvtColor(mat, grayImage, Imgproc.COLOR_BGR2GRAY);

            // Apply adaptive thresholding to the grayscale image
            Mat thresholdedImage = new Mat();
            Imgproc.adaptiveThreshold(grayImage, thresholdedImage, 255, Imgproc.ADAPTIVE_THRESH_GAUSSIAN_C, Imgproc.THRESH_BINARY, 11, 2);

            // Perform noise reduction on the thresholded image
            Mat denoisedImage = new Mat();
            Imgproc.medianBlur(thresholdedImage, denoisedImage, 3);
            recognizeImage(denoisedImage);
            mat = denoisedImage;


//            Bitmap bitmap = Bitmap.createBitmap(mat.cols(), mat.rows(), Bitmap.Config.ARGB_8888);
//            Utils.matToBitmap(mat, bitmap);
//            mTess.setImage(bitmap);
//            String text = mTess.getUTF8Text();
//            Log.d(TAG, "MAT TEXT = "+text);

//            // convert Mat to Bitmap
//            Bitmap bitmap = Bitmap.createBitmap(mat.cols(), mat.rows(), Bitmap.Config.ARGB_8888);
//            Utils.matToBitmap(mat, bitmap);
//            long currentTime = System.currentTimeMillis();
//            double fps = mFrameCounter / ((currentTime - mStartTime) / 1000.0);
//
//            // initialize Tesseract with custom parameters
//            mTess.setPageSegMode(TessBaseAPI.PageSegMode.PSM_AUTO_OSD); // auto page segmentation mode
//            mTess.setVariable("load_system_dawg", "false");
//            mTess.setVariable("load_freq_dawg", "false");
//            mTess.setVariable("load_unambig_dawg", "false");
//            mTess.setVariable("load_punc_dawg", "false");
//            mTess.setVariable("load_number_dawg", "false");
//            mTess.setVariable("load_fixed_length_dawgs", "false");
//            mTess.setVariable("load_bigram_dawg", "false");
//            mTess.setVariable("load_fixed_length_dawgs", "false");
//            mTess.setVariable("tessedit_ocr_engine_mode", "3"); // use both Tesseract and Cube OCR engines
//            mTess.setVariable("language_model_penalty_non_freq_dict_word", "0.05"); // penalty for non-frequent dictionary words
//            mTess.setVariable("language_model_penalty_non_dict_word", "0.1"); // penalty for non-dictionary words
//            mTess.setVariable("textord_tabfind_order", "true"); // find text lines in tabular order
//            mTess.setVariable("tessedit_char_whitelist", "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"); // limit character recognition to alphanumeric characters
//
//            mTess.setImage(bitmap);
//            String text = mTess.getUTF8Text();
//
//            // log text to console
//            Log.d(TAG, "Detected text ("+fps+" fps): " + text);



//            Bitmap bitmap = Bitmap.createBitmap(mat.cols(), mat.rows(), Bitmap.Config.ARGB_8888);
//            Utils.matToBitmap(mat, bitmap);
//
//// Preprocess the image
//
//// Set the image and language model
//            mTess.setPageSegMode(TessBaseAPI.PageSegMode.PSM_SINGLE_BLOCK);
//            mTess.setImage(bitmap);
//
//            String text = mTess.getUTF8Text();
//            Log.d(TAG, "MAT TEXT = "+text);

        }else{
//            mat = frame.gray();
        }
        return mat;
    }




    @Override
    public ViewModelStore getViewModelStore() {
        return viewModelStore;
    }

    public void recognizeImage(Mat mat) {

//        result.setValue("");
//        processing.setValue(true);
//        progress.setValue("Processing...");
        stopped = false;

        // Start process in another thread
        new Thread(() -> {
            Bitmap bitmap = Bitmap.createBitmap(mat.cols(), mat.rows(), Bitmap.Config.ARGB_8888);
            Utils.matToBitmap(mat, bitmap);

            mTess.setImage(bitmap);
            // Or set it as Bitmap, Pix,...
            // tessApi.setImage(imageBitmap);

//            long startTime = SystemClock.uptimeMillis();
//
//            // Use getHOCRText(0) method to trigger recognition with progress notifications and
//            // ability to cancel ongoing processing.
//            mTess.getHOCRText(0);
//
//            // Then get just normal UTF8 text as result. Using only this method would also trigger
//            // recognition, but would just block until it is completed.
            String text = mTess.getUTF8Text();
//
////            result.postValue(text);
//            processing.postValue(false);
//            if (stopped) {
//                progress.postValue("Stopped.");
//            } else {
//                long duration = SystemClock.uptimeMillis() - startTime;
//                progress.postValue(String.format(Locale.ENGLISH,
//                        "Completed in %.3fs.", (duration / 1000f)));
//            }

//            Log.d(TAG, "recognizeImage: result= "+result);
            Log.d(TAG, "MAT TEXT = "+text);
            // Assuming you have a bitmap named "bitmap" and a file name "filename"
            Bitmap bmp32 = bitmap.copy(Bitmap.Config.ARGB_8888, true);
            Utils.bitmapToMat(bmp32, mat);
//            Imgcodecs.imwrite("filename.png", mat);

        }).start();
    }

}